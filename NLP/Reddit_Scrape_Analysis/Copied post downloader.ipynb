{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import time\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"\"  # put the username you want to download in the quotes\n",
    "subreddit = \"Python\"  # put the subreddit you want to download in the quotes\n",
    "# leave either one blank to download an entire user's or subreddit's history\n",
    "# or fill in both to download a specific users history from a specific subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_string = None\n",
    "if username == \"\" and subreddit == \"\":\n",
    "    print(\"Fill in either username or subreddit\")\n",
    "    sys.exit(0)\n",
    "elif username == \"\" and subreddit != \"\":\n",
    "    filter_string = f\"subreddit={subreddit}\"\n",
    "elif username != \"\" and subreddit == \"\":\n",
    "    filter_string = f\"author={username}\"\n",
    "else:\n",
    "    filter_string = f\"author={username}&subreddit={subreddit}\"\n",
    "\n",
    "url = \"https://api.pushshift.io/reddit/{}/search?limit=1000&sort=desc&{}&before=\"\n",
    "\n",
    "start_time = datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFromUrl(filename, object_type):\n",
    "    print(f\"Saving {object_type}s to {filename}\")\n",
    "\n",
    "    count = 0\n",
    "    handle = open(filename, 'w')\n",
    "    previous_epoch = int(start_time.timestamp())\n",
    "    while True:\n",
    "        new_url = url.format(object_type, filter_string)+str(previous_epoch)\n",
    "        json_text = requests.get(new_url, headers={'User-Agent': \"Post downloader by /u/Watchful1\"})\n",
    "        time.sleep(1)  # pushshift has a rate limit, if we send requests too fast it will start returning error messages\n",
    "        try:\n",
    "            json_data = json_text.json()\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        if 'data' not in json_data:\n",
    "            break\n",
    "        objects = json_data['data']\n",
    "        if len(objects) == 0:\n",
    "            break\n",
    "\n",
    "        for object in objects:\n",
    "            previous_epoch = object['created_utc'] - 1\n",
    "            count += 1\n",
    "            if object_type == 'comment':\n",
    "                try:\n",
    "                    handle.write(str(object['score']))\n",
    "                    handle.write(\" : \")\n",
    "                    handle.write(datetime.fromtimestamp(object['created_utc']).strftime(\"%Y-%m-%d\"))\n",
    "                    handle.write(\"\\n\")\n",
    "                    handle.write(object['body'].encode(encoding='ascii', errors='ignore').decode())\n",
    "                    handle.write(\"\\n-------------------------------\\n\")\n",
    "                except Exception as err:\n",
    "                    print(f\"Couldn't print comment: https://www.reddit.com{object['permalink']}\")\n",
    "                    print(traceback.format_exc())\n",
    "            elif object_type == 'submission':\n",
    "                if object['is_self']:\n",
    "                    if 'selftext' not in object:\n",
    "                        continue\n",
    "                    try:\n",
    "                        handle.write(str(object['score']))\n",
    "                        handle.write(\" : \")\n",
    "                        handle.write(datetime.fromtimestamp(object['created_utc']).strftime(\"%Y-%m-%d\"))\n",
    "                        handle.write(\"\\n\")\n",
    "                        handle.write(object['selftext'].encode(encoding='ascii', errors='ignore').decode())\n",
    "                        handle.write(\"\\n-------------------------------\\n\")\n",
    "                    except Exception as err:\n",
    "                        print(f\"Couldn't print post: {object['url']}\")\n",
    "                        print(traceback.format_exc())\n",
    "\n",
    "        print(\"Saved {} {}s through {}\".format(count, object_type, datetime.fromtimestamp(previous_epoch).strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "    print(f\"Saved {count} {object_type}s\")\n",
    "    handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadFromUrl(\"posts.txt\", \"submission\")\n",
    "downloadFromUrl(\"comments.txt\", \"comment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
