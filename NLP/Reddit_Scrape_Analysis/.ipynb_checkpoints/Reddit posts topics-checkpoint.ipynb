{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Topics from Posts in the r/Python subreddit\n",
    "\n",
    "The aim of this project is to classify the topic of posts from the r/Python subreddit from end-to-end. In order to do this, I first needed to scrape a sufficient number of posts for an accurate NLP model. I have done this via this [submission downloader code](https://github.com/dgadish/projects/blob/master/NLP/Reddit_Scrape_Analysis/Reddit%20Submission%20downloader.ipynb) . \n",
    "\n",
    "Once a sufficient number of submissions were scraped, I read them into a pandas dataframe in order to clean them sufficiently to be fed into a model.\n",
    "\n",
    "The submissions were collected at around 10:00 on 07/02/2021\n",
    "\n",
    "The submissions have both title and text sections. I will attempt to determine topics using both. \n",
    "\n",
    "I will attempt to use both LSA (Latent Semantic Analysis) and LDA (Latent Dirichlet Allocation) to determine the topics of each post. When I have more time, I will attempt to use Word Embedding combined with something like K-Means clustering as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_json('python_posts.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python conversion tool for converting csv to J...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1612467290</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lynda courses</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1612466655</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anybody have sample code to determine if a web...</td>\n",
       "      <td>Python</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1612466550</td>\n",
       "      <td>Hi, has anyone created python code that tests ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barnsley Fern - an interesting fractal created...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1612465003</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Project – Find Neapolitan pizza with AI help</td>\n",
       "      <td>Python</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1612464251</td>\n",
       "      <td>Just finished this project! An unfiltered revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit  score  \\\n",
       "1  Python conversion tool for converting csv to J...    Python      1   \n",
       "2                                      lynda courses    Python      1   \n",
       "3  Anybody have sample code to determine if a web...    Python      4   \n",
       "5  Barnsley Fern - an interesting fractal created...    Python      1   \n",
       "6       Project – Find Neapolitan pizza with AI help    Python      2   \n",
       "\n",
       "   num_comments  created_utc  \\\n",
       "1             1   1612467290   \n",
       "2             2   1612466655   \n",
       "3             5   1612466550   \n",
       "5             0   1612465003   \n",
       "6             0   1612464251   \n",
       "\n",
       "                                            selftext  \n",
       "1                                          [removed]  \n",
       "2                                          [removed]  \n",
       "3  Hi, has anyone created python code that tests ...  \n",
       "5                                          [deleted]  \n",
       "6  Just finished this project! An unfiltered revi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26003 entries, 1 to 40100\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         26003 non-null  object\n",
      " 1   subreddit     26003 non-null  object\n",
      " 2   score         26003 non-null  int64 \n",
      " 3   num_comments  26003 non-null  int64 \n",
      " 4   created_utc   26003 non-null  int64 \n",
      " 5   selftext      26003 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "subs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop submissions which have been removed or deleted\n",
    "\n",
    "n_r_d = (subs['selftext'] != '[removed]') & (subs['selftext'] != '[deleted]')\n",
    "subs_1 = subs[n_r_d]\n",
    "subs_1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anybody have sample code to determine if a web...</td>\n",
       "      <td>Python</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1612466550</td>\n",
       "      <td>Hi, has anyone created python code that tests ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project – Find Neapolitan pizza with AI help</td>\n",
       "      <td>Python</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1612464251</td>\n",
       "      <td>Just finished this project! An unfiltered revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In response to the \"Medium bad\" thread, here a...</td>\n",
       "      <td>Python</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1612460552</td>\n",
       "      <td>I agree with some of the sentiments shared in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To open source or not to open source?</td>\n",
       "      <td>Python</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1612453887</td>\n",
       "      <td>When do you guys know when to open source a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can i decrypt signature Url of YouTube Videos</td>\n",
       "      <td>Python</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1612453834</td>\n",
       "      <td>I made a python module which download youtube ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title subreddit  score  \\\n",
       "0  Anybody have sample code to determine if a web...    Python      4   \n",
       "1       Project – Find Neapolitan pizza with AI help    Python      2   \n",
       "2  In response to the \"Medium bad\" thread, here a...    Python      9   \n",
       "3              To open source or not to open source?    Python      3   \n",
       "4  How can i decrypt signature Url of YouTube Videos    Python      2   \n",
       "\n",
       "   num_comments  created_utc  \\\n",
       "0             5   1612466550   \n",
       "1             0   1612464251   \n",
       "2             4   1612460552   \n",
       "3             8   1612453887   \n",
       "4             3   1612453834   \n",
       "\n",
       "                                            selftext  \n",
       "0  Hi, has anyone created python code that tests ...  \n",
       "1  Just finished this project! An unfiltered revi...  \n",
       "2  I agree with some of the sentiments shared in ...  \n",
       "3  When do you guys know when to open source a pr...  \n",
       "4  I made a python module which download youtube ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18102 entries, 0 to 18101\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         18102 non-null  object\n",
      " 1   subreddit     18102 non-null  object\n",
      " 2   score         18102 non-null  int64 \n",
      " 3   num_comments  18102 non-null  int64 \n",
      " 4   created_utc   18102 non-null  int64 \n",
      " 5   selftext      18102 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 848.7+ KB\n"
     ]
    }
   ],
   "source": [
    "subs_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and pre-processing\n",
    "\n",
    "Now that I have collected a sufficiently large data set and dropped any submissions that were deleted or removed, I can begin to clean the data set. For now my cleaning will be focused on preparing the data for a bag-of-words model, suitable for LSA and LDA\n",
    "\n",
    "I will begin with the 'selftext' column and then move to the 'title' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selftext**\n",
    "\n",
    "I will start by removing the url's which are included in a number of the submissions. I have taken a regex expression from [Github Gist user gruber](https://gist.github.com/gruber/8891611). To remove urls with pandas methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a new copy of the dataframe\n",
    "\n",
    "subs_2 = subs_1.copy()\n",
    "\n",
    "# Remove url's with provided regex\n",
    "\n",
    "rgx = r\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\n",
    "subs_2['selftext'] = subs_2['selftext'].str.replace(rgx,\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I shall remove punctuation, tokenize the text and remove any stop words and words less than 4 letters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and convert all to lowercase\n",
    "\n",
    "subs_2['selftext'] = subs_2['selftext'].str.replace('\\W', ' ').str.lower()\n",
    "\n",
    "# Tockenize\n",
    "\n",
    "subs_2['selftext'] = subs_2['selftext'].apply(nltk.word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words and anything less than 4 letters long\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def no_stop(list):\n",
    "    \n",
    "    nostops = []\n",
    "    \n",
    "    for l in list:\n",
    "        if l not in stopwords:\n",
    "            nostops.append(l)\n",
    "    \n",
    "    return nostops\n",
    "\n",
    "            \n",
    "def no_short(list):\n",
    "    \n",
    "    noshort = []\n",
    "    \n",
    "    for l in list:\n",
    "        if len(l) >= 4:\n",
    "            noshort.append(l)\n",
    "    \n",
    "    return noshort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "strin = 'This is a test string to see if my functions work super duper well'\n",
    "strin = nltk.word_tokenize(strin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'test',\n",
       " 'string',\n",
       " 'see',\n",
       " 'functions',\n",
       " 'work',\n",
       " 'super',\n",
       " 'duper',\n",
       " 'well']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stop(strin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'test', 'string', 'functions', 'work', 'super', 'duper', 'well']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_short(strin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply my tested functions to the 'selftext' column\n",
    "\n",
    "subs_2['selftext'] = subs_2['selftext'].apply(no_stop).apply(no_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [anyone, created, python, code, tests, page, d...\n",
       "1    [finished, project, unfiltered, review, pizza,...\n",
       "2    [agree, sentiments, shared, thread, medium, tu...\n",
       "3    [guys, know, open, source, project, working, p...\n",
       "4    [made, python, module, download, youtube, vide...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs_2['selftext'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in processing the data is to lemmetize and stem the words to bring everything into the present tense and remove endings such as 'ed', 'ly', 's' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
